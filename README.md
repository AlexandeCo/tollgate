# ğŸ• Sniff

> *A beagle-nosed local proxy that sniffs your Anthropic API traffic before your token budget runs out.*

```
  / \__
 (    @\___       sniff sniff...
 /         O      something smells like a rate limit
/   (_____/       ğŸ” tokens_remaining: 12,400
/_____/   U
```

**You're burning through your Claude Max budget and you have no idea until it's too late.**

Sniff fixes that. It's a zero-config local proxy that sits between your AI tools and Anthropic's API, reads the rate limit headers on every response, and shows you exactly how close you are to the wall â€” before you hit it.

Works with **Claude Code, Cursor, Continue.dev, Aider, raw API scripts** â€” anything that uses `ANTHROPIC_BASE_URL`. No code changes. No account. No data leaves your machine.

---

## Quickstart

```bash
npx sniff-proxy start
```

Then point your tool at the proxy:

```bash
export ANTHROPIC_BASE_URL=http://localhost:4243
```

For Claude Code, add to `~/.claude/settings.json`:
```json
{ "env": { "ANTHROPIC_BASE_URL": "http://localhost:4243" } }
```

Open your dashboard: **http://localhost:4244** ğŸ•

That's it. Sniff is on the trail.

---

## What You Get

| Feature | Details |
|---------|---------|
| ğŸ“Š **Live token gauge** | Big visual showing % of budget used, color shifts greenâ†’red |
| â±ï¸ **Reset countdown** | Exact time until your rate limit window refreshes |
| ğŸ’° **Cost per call** | Real $ estimated from Anthropic's pricing per model |
| ğŸ” **Live call feed** | Every API call logged: model, tokens in/out, cost, latency |
| ğŸ“ˆ **Burn rate** | Tokens/min so you can project when you'll hit the wall |
| ğŸ¾ **Smart routing** | Auto-downgrades Sonnetâ†’Haiku at 80% budget *(opt-in)* |
| ğŸ¦´ **WOOF alerts** | Browser notifications before you run out |
| ğŸ’¾ **Full history** | SQLite log of every call â€” query it yourself |

---

## Smart Routing (opt-in)

When you're approaching your limit, Sniff can automatically downgrade your model requests to save budget:

```bash
sniff start --routing
```

```
ğŸ¾ Rerouted: sonnet â†’ haiku (tokens at 81%) â€” saving your biscuits
```

The downgrade ladder: `opus â†’ sonnet â†’ haiku`. Transparent to your client â€” we just swap the model field before forwarding.

---

## Why Not LangSmith / Helicone / AgentOps?

| | Sniff | Others |
|--|-------|--------|
| Local-first | âœ… Your machine only | âŒ Cloud/SaaS |
| Zero code changes | âœ… One env var | âŒ Requires SDK |
| Works with any tool | âœ… Proxy-based | âŒ Per-SDK instrumentation |
| Rate-limit focus | âœ… First-class | âŒ Afterthought |
| Free & open source | âœ… MIT | âŒ Paid tiers |

---

## Dashboard

<img alt="Sniff dashboard preview" src="https://github.com/AlexandeCo/sniff/raw/main/docs/preview.png" width="600">

*(screenshot coming soon â€” the beagle is working on it)*

---

## Install Globally

```bash
npm install -g sniff-proxy
sniff start
```

## CLI Options

```
sniff start              Start proxy + dashboard
sniff start --routing    Enable smart model routing at 80% budget
sniff start --port 4243  Custom proxy port (default: 4243)
sniff start --dash 4244  Custom dashboard port (default: 4244)
sniff status             Show current rate limit state
```

---

## Configuration

Config lives at `~/.config/sniff-proxy/config.json`:

```json
{
  "proxy": { "port": 4243 },
  "dashboard": { "port": 4244, "autoOpen": true },
  "routing": {
    "enabled": false,
    "threshold": 80,
    "ladder": {
      "claude-opus-4-6": "claude-sonnet-4-6",
      "claude-sonnet-4-6": "claude-haiku-4-6"
    }
  },
  "alerts": {
    "tokenWarningPercent": 80,
    "tokenCriticalPercent": 95
  }
}
```

---

## Beagle Philosophy ğŸ•

Beagles don't miss anything. They follow the trail, sound the alarm, and never stop until the job is done.

That's Sniff. It watches every call. It knows when you're getting close. And it'll bark before you hit the wall.

*Good boy.*

---

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md). The one rule: don't break the zero-config promise.

## License

MIT Â© [AlexandeCo](https://github.com/AlexandeCo)
